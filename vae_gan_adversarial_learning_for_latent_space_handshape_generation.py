# -*- coding: utf-8 -*-
"""VAE-GAN Adversarial Learning for Latent Space Handshape Generation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jp7M9vwW1IjArfKxXGJdUlWsYK0XsimZ

# **VAE-GAN Adversarial Learning for Latent Space Handshape Generation**

The aim of this project is to implement and validate a VAE-GAN as per the original paper by ABL Larsen et al to achieve latent space handshape generation
https://arxiv.org/abs/1512.09300

<img src="https://miro.medium.com/max/2992/0*KEmfTtghsCDu6UTb.png" width="400">

# **Import packages**
"""

import os
import torch
import torch.nn as nn
import numpy as np
import nibabel as nib
import matplotlib.pyplot as plt

from glob import glob
from os.path import join
from os import listdir
from pathlib import Path


from torch import optim
from torch.utils.data.dataset import Dataset
from torch.utils.data.dataloader import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data import DataLoader
from torch.nn.modules.loss import L1Loss
from torch.nn.modules.loss import MSELoss

from collections import OrderedDict
import torch.nn.functional as F
from torch.nn.modules.loss import BCELoss


def numpy_from_tensor(x):
  return x.detach().cpu().numpy()

file_download_link = "https://docs.google.com/uc?export=download&id=1lsCyvsaZ2GMxkY5QL5HFz-I40ihmtE1K"
!wget -O ImagesHands.zip --no-check-certificate "$file_download_link"
!unzip ImagesHands.zip

from google.colab import drive
drive.mount('/content/drive')

!unzip '/content/drive/My Drive/AML-PJ2/ImagesHands.zip' -d '/content/drive/My Drive/AML-PJ2/ImagesHands'

"""# **Dataset and Dataloader**"""

class NiftyDataset(Dataset):
  '''
    Class that loads nii files, resizes them to 96x96 and feeds them
  '''
  def __init__(self,root_dir):
    '''
      root_dir - string - path towards the folder containg the data
    '''
    # Save the root_dir as a class variable
    self.root_dir = root_dir
    # Save the filenames in the root_dir as a class variable
    self.filenames = listdir(self.root_dir)

  def __len__(self):
    return len(self.filenames)

  def __getitem__(self,idx):
    # Fetch file filename
    img_name = self.filenames[idx]
    # Load the nifty image
    img = nib.load(os.path.join(self.root_dir,img_name))
    # Get the voxel values as a numpy array
    img = np.array(img.get_fdata())
    # Expanding the array with 1 new dimension as feature channel
    img = np.expand_dims(img, 0)
    return img

# Loading the data
dataset = NiftyDataset(
    root_dir=join('/content/drive/My Drive/AML-CW2/ImagesHands/nii'
                    )
)

# Create the required DataLoaders for training and testing
dataset_loader = DataLoader(
    dataset,
    shuffle=True,
    batch_size=4,
    num_workers=4,
    drop_last=True
)

# Show a random image from training
plt.imshow(np.squeeze(next(iter(dataset))), cmap="gray")
plt.axis('off')
plt.show()

"""# Encoder & Decoder


"""

class ResBlock(nn.Module):
  def __init__(self, in_channels, out_channels, mode="level"):
    super(ResBlock, self).__init__()

    # Check if the mode is upsampling or not to determine convolutional layers
    if mode == "upsample":
      self.conv1 = nn.ConvTranspose2d(
          in_channels=in_channels,
          out_channels=out_channels,
          kernel_size=4,
          stride=2 ,
          padding=1,
      )

      self.conv1b = nn.ConvTranspose2d(
          in_channels=in_channels,
          out_channels=out_channels,
          kernel_size=4,
          stride=2 ,
          padding=1,
      )
    # Otherwise, use standard convolutional layers
    else:
      self.conv1 = nn.Conv2d(
          in_channels=in_channels,
          out_channels=out_channels,
          kernel_size=3,
          stride=2 if mode == "downsample" else 1,
          padding=1,
      )

      self.conv1b = nn.Conv2d(
          in_channels=in_channels,
          out_channels=out_channels,
          kernel_size=3,
          stride=2 if mode == "downsample" else 1,
          padding=1,
      )

    # Second convolutional layer
    self.conv2 =  nn.Conv2d(
        in_channels=out_channels,
        out_channels=out_channels,
        kernel_size=3,
        stride=1,
        padding=1,
    )

    # Activation function
    self.activation = nn.LeakyReLU(inplace=False)

    # Initialize weights using Xavier initialization
    torch.nn.init.xavier_normal_(self.conv1.weight.data)
    torch.nn.init.xavier_normal_(self.conv1b.weight.data)
    torch.nn.init.xavier_normal_(self.conv2.weight.data)

  # Forward pass
  def forward(self, x):
    out = self.conv1(x) # First convolutional layer
    out = self.activation(out) # Activation function

    skip = self.conv1b(x) # Convolutional layer for the skip connection

    out = self.conv2(out) # Second convolutional layer
    out += skip # Add the skip connection

    out = self.activation(out) # Activation function

    return out

class Encoder(nn.Module):
  def __init__(self, in_channels, depth, length, feature_size):
    super(Encoder, self).__init__()

    # Sequential container for the encoder network
    encoder = nn.Sequential()

    # Initial convolutional layer
    encoder.add_module(
        "encoder-initial-conv",
        nn.Conv2d(
            in_channels=in_channels,
            out_channels=feature_size,
            kernel_size=3,
            stride=1,
            padding=1,
        )
    )
    encoder.add_module(
        "encoder-initial-activation",
        nn.LeakyReLU(inplace=False)
    )

    # Loop over each depth level
    for d in range(depth):
        # Residual blocks at the current depth level
        for l in range(length):
            encoder.add_module(
                f"encoder-depth-{d}-resblock-{l}",
                ResBlock(
                    in_channels=feature_size,
                    out_channels=feature_size,
                    mode="level",
                )
            )

        # Downsampling block at the current depth level
        encoder.add_module(
            f"encoder-depth-{d}-downsample",
            ResBlock(
                in_channels=feature_size,
                out_channels=feature_size * 2,
                mode="downsample",
            )
        )
        feature_size *= 2

    self.encoder = encoder

  def forward(self, x):
    return self.encoder(x)

class Decoder(nn.Module):
  def __init__(self, in_channels, depth, length, reconstruction_channels):
    super(Decoder, self).__init__()

    decoder = nn.Sequential()

    # Residual blocks at the current depth level
    for d in range(depth):
        for l in range(length):
            decoder.add_module(
                f"decoder-depth-{d}-resblock-{l}",
                ResBlock(
                    in_channels=in_channels,
                    out_channels=in_channels,
                    mode="level",
                )
            )

        # upsampling block at the current depth level
        decoder.add_module(
            f"decoder-depth-{d}-upsample",
            ResBlock(
                in_channels=in_channels,
                out_channels=in_channels // 2,
                mode="upsample",
            )
        )
        in_channels //= 2

    # Final convolutional layer
    decoder.add_module(
        "decoder-final-conv",
        nn.Conv2d(
            in_channels=in_channels,
            out_channels=reconstruction_channels,
            kernel_size=3,
            stride=1,
            padding=1,
        )
    )

    self.decoder = decoder

  def forward(self, x):
    return self.decoder(x)

"""### REPORT

This architecture above is still an encoder-decoder architecture with ResBlocks as the building blocks. The encoder reduces the spatial dimensions of the input data while increasing the number of feature channels, and the decoder increases the spatial dimensions of the input data while decreasing the number of feature channels. The ResBlock is still the same as before, with two convolutional layers and a skip connection that adds the output of the first layer to the output of the second layer.

The reason for using this architecture is that ResBlocks are effective building blocks for deep neural networks. ResBlocks allow the network to learn complex functions by passing information through skip connections, which helps to mitigate the vanishing gradient problem. This architecture also benefits from the use of residual connections and batch normalization, which helps to improve training stability and convergence speed.

There are other design decisions that could have been made when designing an encoder-decoder architecture for unsupervised learning tasks. For example, Choosing the number and size of the ResBlocks. The number and size of the ResBlocks used in the architecture can affect the network's ability to learn complex functions and its computational efficiency. Increasing the number of ResBlocks can help the network learn more complex functions, but it may also increase the risk of overfitting and slow down training. Choosing a smaller size for the ResBlocks can reduce the number of parameters and improve computational efficiency, but it may also limit the network's ability to learn complex functions.

# Adversarial Learning (discriminator)
"""

class Discriminator(nn.Module):
    def __init__(self, img_shape=(1, 256, 256), num_filters=64, num_layers=4):
        super(Discriminator, self).__init__()

        self.num_layers = num_layers
        self.num_filters = num_filters

        # calculate the size of the input tensor for the first conv layer
        input_size = img_shape[-1] // (2**num_layers)
        self.input_shape = (img_shape[0], self.num_filters, input_size, input_size)

        self.conv_layers = nn.ModuleList()
        self.bn_layers = nn.ModuleList()

        # create convolutional and batch norm layers for each layer in the discriminator
        for i in range(num_layers):
            in_channels = self.num_filters * (2**(i-1)) if i > 0 else img_shape[0]
            out_channels = self.num_filters * (2**i)

            conv_layer = nn.Conv2d(
                in_channels=in_channels,
                out_channels=out_channels,
                kernel_size=4,
                stride=2,
                padding=1,
                bias=False
            )

            bn_layer = nn.BatchNorm2d(num_features=out_channels)

            self.conv_layers.append(conv_layer)
            self.bn_layers.append(bn_layer)

        # final linear layer to output a single scalar value
        self.linear = nn.Linear(out_channels * input_size * input_size, 1)

    def forward(self, img):
        out = img

        # pass the image through each convolutional and batch norm layer
        for i in range(self.num_layers):
            out = self.conv_layers[i](out)
            out = self.bn_layers[i](out)
            out = F.leaky_relu(out, negative_slope=0.2)

        # flatten the output tensor and pass it through the final linear layer
        out = out.view(out.shape[0], -1)
        out = self.linear(out)

        # apply sigmoid activation to output the probability that the input is real
        validity = torch.sigmoid(out)
        return validity

"""### REPORT

As the task of the discriminator is to classify whether an image is real or fake, I started by using a similar architecture to the one proposed in Larsen et al., but with some modifications. It uses a similar structure with convolutional layers and batch normalization, but also adds a final linear layer to output a single scalar value.

The decision to use a deeper architecture with more filters per layer is motivated by the need to learn more complex features from the input images and to improve discrimination performance. By increasing the depth and the number of filters, the discriminator can better capture the hierarchical structure of the input images and distinguish between real and fake samples.

Designing a good architecture for a discriminator involves finding a balance between depth, width, and other architectural choices such as activation functions, normalization layers, and pooling or striding operations. Deep architectures can learn more complex features, but they may also be prone to overfitting or vanishing gradients. Wider architectures with more filters per layer can improve discrimination performance, but they may also require more computational resources and suffer from slower training. The choice of activation function, normalization layer, and pooling or striding operation can also affect discrimination performance by influencing the expressivity and generalization ability of the model.

# Code Processor and Network

In order to obtain a VAE-GAN, We need to implement a the VAE code processor using either a Dense AutoEncoder or a spatial Code Processor. And glue the encoder, decoder decriminator and code processor into a single network.
"""

class SpatialVAECodeProcessor(nn.Module):
    def __init__(self, feature_size, depth, is_training):
        super(SpatialVAECodeProcessor, self).__init__()
        self.logvars_upper_bound = 50
        self.logvars_lower_bound = -self.logvars_upper_bound
        self.is_training = is_training

        feature_depth = feature_size * 2**(depth)

        self.logvar = nn.Conv2d(
            in_channels=feature_depth,
            out_channels=feature_depth,
            kernel_size=3,
            stride=1,
            padding=1,
        )

        self.mu = nn.Conv2d(
            in_channels=feature_depth,
            out_channels=feature_depth,
            kernel_size=3,
            stride=1,
            padding=1,
        )

    def forward(self, x):
        logvar = torch.clamp(
            self.logvar(x),
            self.logvars_lower_bound,
            self.logvars_upper_bound
        )

        mu = self.mu(x)

        if self.is_training:
            std = logvar.mul(0.5).exp_()
            esp = torch.randn_like(mu)
            x = mu + std * esp
        else:
            x = mu

        return x, mu, logvar

    def encode(self, x):
        x, mu, logvar = self.forward(x)
        return x, mu, logvar

    def decode(self, x):
        return x

    def set_is_training(self, is_training):
        self.is_training = is_training

class VAE_GAN(nn.Module):
    def __init__(self, encoder, code_processor, decoder, discriminator, is_vae):
        super(VAE_GAN, self).__init__()
        self.is_vae = is_vae
        self.is_training = True
        self.encoder = encoder
        self.code_processor = code_processor
        self.decoder = decoder
        self.discriminator = discriminator

    def forward(self, x):
        x = self.encoder(x)

        if self.is_vae:
            x, mu, logvar = self.code_processor(x)
        else:
            x = self.code_processor(x)
            mu, logvar = None, None

        x = self.decoder(x)

        if self.is_vae:
            return x, mu, logvar, self.discriminator(x)
        else:
            return x, self.discriminator(x)

    def encode(self, x):
        x = self.encoder(x)
        x = self.code_processor.encode(x)

        return x

    def decode(self, x):
        x = self.code_processor.decode(x)
        x = self.decoder(x)

        return x

    def set_is_training(self, is_training):
        self.is_training = is_training
        self.code_processor.set_is_training(is_training)

"""### REPORT

For the VAE code processor, I have chosen the Spatial Code Processor as it makes use of 2D Convolutional layers for the logvar and mean, which is more suitable for processing image data.

The overall network architecture is a VAE-GAN, where the encoder, decoder, and discriminator are all connected. The encoder takes in an input image and encodes it into a latent representation. This latent representation is then fed into the code processor which is responsible for applying the reparameterization trick and producing the latent code for the decoder. The decoder then takes this code and reconstructs the image.

In addition to the reconstruction loss used in the VAE, I also use an adversarial loss to improve the quality of the generated images. The adversarial loss is calculated using the discriminator, which is trained to distinguish between real and generated images. The generator is trained to produce images that can fool the discriminator into thinking that they are real.

# Training Loop
"""

# Define the indices to split the dataset
num_samples = len(dataset)
indices = list(range(num_samples))
split = int(np.floor(0.8 * num_samples))  # 80-20 split
np.random.shuffle(indices)
train_indices, test_indices = indices[:split], indices[split:]

# Define the samplers to sample from the indices
train_sampler = SubsetRandomSampler(train_indices)
test_sampler = SubsetRandomSampler(test_indices)

# Define the data loaders with the samplers
train_loader = DataLoader(
    dataset,
    batch_size=4,
    num_workers=4,
    drop_last=True,
    sampler=train_sampler
)
test_loader = DataLoader(
    dataset,
    shuffle=False,
    batch_size=4,
    num_workers=4,
    drop_last=True,
    sampler=test_sampler
)

lr=0.0001
b1=0.5
b2=0.999
EPOCHS = 50

# Training loop for the VAE-GAN
def train_network(training_loader, testing_loader, network, is_vae, gamma):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    network.to(device)

    # Initialize the optimizer for the generator and discriminator
    optimizer_G = torch.optim.Adam(network.decoder.parameters(), lr=lr, betas=(b1, b2))
    optimizer_D = torch.optim.Adam(network.discriminator.parameters(), lr=lr, betas=(b1, b2))

    l1_loss = L1Loss()
    l2_loss = MSELoss()
    # Initialize the adversarial loss function
    adversarial_loss = nn.BCELoss()

    # Train the network
    for epoch in range(EPOCHS):
        for x in training_loader:
            # Move input to device
            x = x.to(device, dtype=torch.float)

            # Zero the parameter gradients
            optimizer_G.zero_grad()
            optimizer_D.zero_grad()

            # Forward pass
            if is_vae:
                z, mu, logvar = network.encode(x)
                x_hat = network.decode(z)
                D_x_hat = network.discriminator(x_hat)
            else:
                z = network.encode(x)
                x_hat = network.decode(z)
                D_x_hat = network.discriminator(x_hat)

            # Reconstruction loss
            rec_loss = l1_loss(x, x_hat) + l2_loss(x, x_hat)

            # Adversarial loss
            G_loss = adversarial_loss(D_x_hat, torch.ones_like(D_x_hat))

            # Total generator loss
            G_loss = rec_loss + gamma * G_loss

            # Backward pass
            G_loss.backward(retain_graph=True)
            optimizer_G.step()

            if is_vae:
                # KL-divergence
                logvar = torch.flatten(logvar, start_dim=1)
                mu = torch.flatten(mu, start_dim=1)
                kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                kl_div = kl_div.mean()

                # Total discriminator loss
                D_loss = adversarial_loss(network.discriminator(x), torch.ones_like(D_x_hat)) + \
                         adversarial_loss(D_x_hat.detach(), torch.zeros_like(D_x_hat))

                # Backward pass
                D_loss.backward()
                optimizer_D.step()

            # Print progress
            if epoch % 10 == 0:
              with torch.no_grad():
                  # Turn the network in testing mode
                  network.set_is_training(is_training=False)

                  # Initialize accumulators
                  l1_test_loss = 0
                  l2_test_loss = 0
                  kl_test_loss = 0
                  adv_test_loss = torch.zeros(1, device=device)
                  for i, x in enumerate(testing_loader):
                      x = x.to(device, dtype=torch.float)

                      # Forward pass
                      if is_vae:
                          z, mu, logvar = network.encode(x)
                          x_hat = network.decode(z)
                          D_x_hat = network.discriminator(x_hat)
                      else:
                          z = network.encode(x)
                          x_hat = network.decode(z)
                          D_x_hat = network.discriminator(x_hat)

                      # Reconstruction loss
                      l1_test_loss += l1_loss(x, x_hat)
                      l2_test_loss += l2_loss(x, x_hat)

                      if is_vae:
                          # KL-divergence
                          logvar = torch.flatten(logvar, start_dim=1)
                          mu = torch.flatten(mu, start_dim=1)
                          kl_div_test = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                          kl_test_loss += kl_div_test.mean()

                          # Adversarial loss
                          adv_test_loss += adversarial_loss(D_x_hat, torch.ones_like(D_x_hat))

                  # Print results
                  if is_vae:
                      print(
                          "==== Epoch: " + str(epoch) +
                          " | L1 loss: " + str(numpy_from_tensor(l1_test_loss/i)) +
                          " | L2 loss: " + str(numpy_from_tensor(l2_test_loss/i)) +
                          " | KL loss: " + str(numpy_from_tensor(kl_test_loss/i)) +
                          " | Adv loss: " + str(numpy_from_tensor(adv_test_loss/i)) +
                          " | Total Loss: " + str(numpy_from_tensor((l1_test_loss+l2_test_loss+gamma*adv_test_loss+kl_test_loss)/i))+ " =====")
                  else:
                      print(
                          "==== Epoch: " + str(epoch) +
                          " | L1 loss: " + str(numpy_from_tensor(l1_test_loss/i)) +
                          " | L2 loss: " + str(numpy_from_tensor(l2_test_loss/i)) +
                          " | Adv loss: " + str(numpy_from_tensor(adv_test_loss/i)) +
                          " | Total Loss: " + str(numpy_from_tensor((l1_test_loss+l2_test_loss+gamma*adv_test_loss)/i))+ " =====")


              # Turn the network back into training mode
              network.set_is_training(is_training=True)

# Initial network parameters
network = VAE_GAN(
    encoder=Encoder(
      in_channels=1,
      depth=5,
      length=2,
      feature_size=8
    ),
    decoder=Decoder(
      in_channels=8 * (2 ** 5),
      depth=5,
      length=2,
      reconstruction_channels=1
    ),
    code_processor=SpatialVAECodeProcessor(
       feature_size=8,
       depth=5,
       is_training=True
    ),
    is_vae=True,
    discriminator=Discriminator(),
  )

# Train the network
train_network(train_loader, test_loader, network, is_vae=True, gamma=0.1)

"""### REPORT

The training loop trains a VAE-GAN Network on a training dataset and evaluates the network's performance on a testing dataset. The loop consists of two nested loops. The outer loop runs for a specified number of epochs and the inner loop iterates through each batch of samples in the training dataset.

For each batch, the code moves the input data to the device, performs a forward pass through the model to get the output and computes the reconstruction loss and adversarial loss. It then computes the total generator loss as a combination of the two losses and performs a backward pass through the generator to update its parameters. If the model is a VAE, the code also computes the KL-divergence loss and the discriminator loss and performs a backward pass through the discriminator to update its parameters.

After each epoch, the code enters testing mode and loops through each batch of samples in the testing dataset. For each batch, it performs a forward pass through the model to get the output and compute the reconstruction loss, KL-divergence loss, and adversarial loss. It then accumulates these losses and prints the average losses over the entire testing dataset. In a generative model like a Variational Autoencoder (VAE), the KL loss term encourages the latent distribution of the model to match a prior distribution, usually a standard normal distribution. This term is used to regularize the model and prevent it from overfitting to the training data by making the model's latent representation more structured and easier to sample from.

I noticed that the original code was missing some necessary imports, such as BCELoss for the part of adversarial loss. By training and evaluating the model several times, I set the learning rate to 0.001; the β parameter in the Adam optimiser controls the exponential decay rate at the first and second moments of the gradient, with β1 values set to 0.5 and β2 values set to 0.999; the gamma parameter in the adversarial loss controls the relative weight of the adversarial loss, which affects the balance between the reconstruction and the adversarial objective, with gamma to 0.1; the latent dimension controls the size of the latent space, which can affect the model's ability to capture the underlying structure of the data. Also i set the epoch is 50. In summary, these hyperparameter values allow the best performance to be produced on the test dataset. The very small range of variation in the KL loss term during training indicates that the model did not deviate significantly from the prior distribution and that the model was not over-fitted.

# Reconstruction Visualisation & Metrics

Feed some data to display the input and the reconstructed image after being encoded and decoded. Also estimate the mean squared error between the images as a metric describing the performance of the method.
"""

def display_results(x, x_hat):
  x = numpy_from_tensor(x[0])
  x_hat = numpy_from_tensor(x_hat[0])

  plt.figure()
  f, axarr = plt.subplots(1, 3)

  axarr[0].imshow(np.squeeze(x), cmap="gray")
  axarr[0].axis('off')
  axarr[0].title.set_text("Input")

  axarr[1].imshow(np.squeeze(x-x_hat), cmap="gray")
  axarr[1].axis('off')
  axarr[1].title.set_text("Residual")

  axarr[2].imshow(np.squeeze(x_hat), cmap="gray")
  axarr[2].axis('off')
  axarr[2].title.set_text("Reconstruction")

  plt.show()

def vae_gan_train_network(training_loader, testing_loader, network, is_vae, gamma):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    network.to(device)

    # Initialize the optimizer for the generator and discriminator
    optimizer_G = torch.optim.Adam(network.decoder.parameters(), lr=lr, betas=(b1, b2))
    optimizer_D = torch.optim.Adam(network.discriminator.parameters(), lr=lr, betas=(b1, b2))

    l1_loss = L1Loss()
    l2_loss = MSELoss()
    # Initialize the adversarial loss function
    adversarial_loss = nn.BCELoss()

    # Train the network
    for epoch in range(EPOCHS):
        for x in training_loader:
            # Move input to device
            x = x.to(device, dtype=torch.float)

            # Zero the parameter gradients
            optimizer_G.zero_grad()
            optimizer_D.zero_grad()

            # Forward pass
            if is_vae:
                z, mu, logvar = network.encode(x)
                x_hat = network.decode(z)
                D_x_hat = network.discriminator(x_hat)
            else:
                z = network.encode(x)
                x_hat = network.decode(z)
                D_x_hat = network.discriminator(x_hat)

            # Reconstruction loss
            rec_loss = l1_loss(x, x_hat) + l2_loss(x, x_hat)

            # Adversarial loss
            G_loss = adversarial_loss(D_x_hat, torch.ones_like(D_x_hat))

            # Total generator loss
            G_loss = rec_loss + gamma * G_loss

            # Backward pass
            G_loss.backward(retain_graph=True)
            optimizer_G.step()



            if is_vae:
                # KL-divergence
                logvar = torch.flatten(logvar, start_dim=1)
                mu = torch.flatten(mu, start_dim=1)
                kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                kl_div = kl_div.mean()

                # Total discriminator loss
                D_loss = adversarial_loss(network.discriminator(x), torch.ones_like(D_x_hat)) + \
                         adversarial_loss(D_x_hat.detach(), torch.zeros_like(D_x_hat))

                # Backward pass
                D_loss.backward()
                optimizer_D.step()


            # Print progress
            if epoch % 10 == 0:
              with torch.no_grad():
                  # Turn the network in testing mode
                  network.set_is_training(is_training=False)

                  # Initialize accumulators
                  l1_test_loss = 0
                  l2_test_loss = 0
                  kl_test_loss = 0
                  adv_test_loss = torch.zeros(1, device=device)
                  for i, x in enumerate(testing_loader):
                      x = x.to(device, dtype=torch.float)

                      # Forward pass
                      if is_vae:
                          z, mu, logvar = network.encode(x)
                          x_hat = network.decode(z)
                          D_x_hat = network.discriminator(x_hat)
                      else:
                          z = network.encode(x)
                          x_hat = network.decode(z)
                          D_x_hat = network.discriminator(x_hat)

                      # Reconstruction loss
                      l1_test_loss += l1_loss(x, x_hat)
                      l2_test_loss += l2_loss(x, x_hat)

                      if is_vae:
                          # KL-divergence
                          logvar = torch.flatten(logvar, start_dim=1)
                          mu = torch.flatten(mu, start_dim=1)
                          kl_div_test = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                          kl_test_loss += kl_div_test.mean()

                          # Adversarial loss
                          adv_test_loss += adversarial_loss(D_x_hat, torch.ones_like(D_x_hat))

                  # Print results
                  if is_vae:
                      print(
                          "==== Epoch: " + str(epoch) +
                          " | L1 loss: " + str(numpy_from_tensor(l1_test_loss/i)) +
                          " | L2 loss: " + str(numpy_from_tensor(l2_test_loss/i)) +
                          " | KL loss: " + str(numpy_from_tensor(kl_test_loss/i)) +
                          " | Adv loss: " + str(numpy_from_tensor(adv_test_loss/i)) +
                          " | Total Loss: " + str(numpy_from_tensor((l1_test_loss+l2_test_loss+gamma*adv_test_loss+kl_test_loss)/i))+ " =====")
                  else:
                      print(
                          "==== Epoch: " + str(epoch) +
                          " | L1 loss: " + str(numpy_from_tensor(l1_test_loss/i)) +
                          " | L2 loss: " + str(numpy_from_tensor(l2_test_loss/i)) +
                          " | Adv loss: " + str(numpy_from_tensor(adv_test_loss/i)) +
                          " | Total Loss: " + str(numpy_from_tensor((l1_test_loss+l2_test_loss+gamma*adv_test_loss)/i))+ " =====")

                  # Display some results
                  display_results(x, x_hat)

              # Turn the network back into training mode
              network.set_is_training(is_training=True)

# Initial network parameters
network = VAE_GAN(
    encoder=Encoder(
      in_channels=1,
      depth=5,
      length=2,
      feature_size=8
    ),
    decoder=Decoder(
      in_channels=8 * (2 ** 5),
      depth=5,
      length=2,
      reconstruction_channels=1
    ),
    code_processor=SpatialVAECodeProcessor(
       feature_size=8,
       depth=5,
       is_training=True
    ),
    is_vae=True,
    discriminator=Discriminator(),
  )

# Train the network
vae_gan_train_network(train_loader, test_loader, network, is_vae=True, gamma=0.1)

"""### REPORT

In 50 epochs of training, the reconstructed images were visualised by reconstructing them with relatively clear features and relatively high levels of noise or distortion when compared to the input images. This suggests that the quality of the reconstruction is not very good over the 50 epochs. It may be that using mean squared error as a loss function leads to blurring, or it may be that the 50 epochs experienced for training are not sufficient to produce a reconstructed image that is visually similar to the real image and it is also possible that the division of the dataset into an 80% training set and a 20% test set made the test dataset too small resulting in poor quality reconstructed images. However, the numerical results based on the loss term suggest that the model is effectively learning to capture the salient features of the input data and produce a realistic output.

To observe the reconstruction loss, such as L1 loss and L2 loss, and the adversarial loss, such as the confrontation loss, to decrease over time during training. This is because the model is gradually learning to better reconstruct the input data and produce more realistic outputs. However, the KL loss, which measures the divergence between the learned latent distribution and a prior distribution, it not changes much over time during training. This indicates that the model does not deviate significantly from the prior distribution and that the model has not been over-fitted.

#Comparison to the standard VAE (without the GAN loss)
"""

class VAE(nn.Module):
    def __init__(self, encoder, code_processor, decoder, is_vae):
        super(VAE, self).__init__()
        self.is_vae = is_vae
        self.is_training = True
        self.encoder = encoder
        self.code_processor = code_processor
        self.decoder = decoder

    def forward(self, x):
        x = self.encoder(x)

        if self.is_vae:
            x, mu, logvar = self.code_processor(x)
        else:
            x = self.code_processor(x)
            mu, logvar = None, None

        x = self.decoder(x)

        if self.is_vae:
            return x, mu, logvar
        else:
            return x

    def encode(self, x):
        x = self.encoder(x)
        x = self.code_processor.encode(x)

        return x

    def decode(self, x):
        x = self.code_processor.decode(x)
        x = self.decoder(x)

        return x

    def set_is_training(self, is_training):
        self.is_training = is_training
        self.code_processor.set_is_training(is_training)

def vae_train_network(train_loader, test_loader, network, is_vae, gamma):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    network.to(device)

    # Initialize the optimizer for the generator
    optimizer_G = torch.optim.Adam(network.decoder.parameters(), lr=lr, betas=(b1, b2))

    l1_loss = L1Loss()
    l2_loss = MSELoss()


    # Train the network
    for epoch in range(EPOCHS):
        for x in train_loader:
            # Move input to device
            x = x.to(device, dtype=torch.float)

            # Zero the parameter gradients
            optimizer_G.zero_grad()

            # Forward pass
            if is_vae:
                z, mu, logvar = network.encode(x)
                x_hat = network.decode(z)
            else:
                z = network.encode(x)
                x_hat = network.decode(z)

            # Reconstruction loss
            rec_loss = l1_loss(x, x_hat) + l2_loss(x, x_hat)


            if is_vae:
                # KL-divergence
                logvar = torch.flatten(logvar, start_dim=1)
                mu = torch.flatten(mu, start_dim=1)
                kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                kl_div = kl_div.mean()

                # Total loss
                loss = rec_loss + gamma * kl_div

                # Backward pass
                loss.backward()
                optimizer_G.step()


            # Print progress
            if epoch % 10  == 0:
              with torch.no_grad():
                  # Turn the network in testing mode
                  network.set_is_training(is_training=False)

                  # Initialize accumulators
                  l1_test_loss = 0
                  l2_test_loss = 0
                  kl_test_loss = 0
                  # adv_test_loss = torch.zeros(1, device=device)
                  for i, x in enumerate(test_loader):
                      x = x.to(device, dtype=torch.float)

                      # Forward pass
                      if is_vae:
                          z, mu, logvar = network.encode(x)
                          x_hat = network.decode(z)
                      else:
                          z = network.encode(x)
                          x_hat = network.decode(z)

                      # Reconstruction loss
                      l1_test_loss += l1_loss(x, x_hat)
                      l2_test_loss += l2_loss(x, x_hat)

                      if is_vae:
                          # KL-divergence
                          logvar = torch.flatten(logvar, start_dim=1)
                          mu = torch.flatten(mu, start_dim=1)
                          kl_div_test = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                          kl_test_loss += kl_div_test.mean()


                  # Print results
                  if is_vae:
                      print(
                          "==== Epoch: " + str(epoch) +
                          " | L1 loss: " + str(numpy_from_tensor(l1_test_loss/i)) +
                          " | L2 loss: " + str(numpy_from_tensor(l2_test_loss/i)) +
                          " | KL loss: " + str(numpy_from_tensor(kl_test_loss/i)) +
                          " | Total Loss: " + str(numpy_from_tensor((l1_test_loss+l2_test_loss+gamma*kl_test_loss)/i))+ " =====")
                  else:
                      print(
                          "==== Epoch: " + str(epoch) +
                          " | L1 loss: " + str(numpy_from_tensor(l1_test_loss/i)) +
                          " | L2 loss: " + str(numpy_from_tensor(l2_test_loss/i)) +
                          " | Total Loss: " + str(numpy_from_tensor((l1_test_loss+l2_test_loss)/i))+ " =====")

                  # Display some results
                  display_results(x, x_hat)

              # Turn the network back into training mode
              network.set_is_training(is_training=True)

# Initial network parameters
network = VAE(
    encoder=Encoder(
      in_channels=1,
      depth=5,
      length=2,
      feature_size=8
    ),
    decoder=Decoder(
      in_channels=8 * (2 ** 5),
      depth=5,
      length=2,
      reconstruction_channels=1
    ),
    code_processor=SpatialVAECodeProcessor(
       feature_size=8,
       depth=5,
       is_training=True
    ),
    is_vae=True,
  )

# Train the network
vae_train_network(train_loader, test_loader, network, is_vae=True, gamma=0.1)

"""### REPORT

Based on the reconstructed visualisation results obtained from training the VAE and VAE-GAN models, the reconstructed images produced by the VAE model and the reconstructed images produced by the VAE-GAN model did not achieve visual similarity to the real images. This indicates that it could still be due to the hyperparameters not being optimally tuned.

From the numerical results, the VAE model produces better reconstructions than the VAE-GAN model. the VAE model achieves a lower reconstruction loss than the VAE-GAN model. This may be due to the fact that the VAE model only needs to optimise for reconstruction loss, whereas the VAE-GAN model needs to optimise for both reconstruction and adversarial loss, which causes VAE-GAN to sacrifice some reconstruction quality in order to improve the quality of the generated samples.

Overall, if the goal is to generate high quality samples, then the VAE-GAN model may be more appropriate. However, if the goal is to obtain high quality reconstructions, then the VAE model may be more appropriate.

# Generate Samples
"""

# Define the VAE model
vae_model = VAE(
    encoder=Encoder(
      in_channels=1,
      depth=5,
      length=2,
      feature_size=8
    ),
    decoder=Decoder(
      in_channels=8 * (2 ** 5),
      depth=5,
      length=2,
      reconstruction_channels=1
    ),
    code_processor=SpatialVAECodeProcessor(
       feature_size=8,
       depth=5,
       is_training=True
    ),
    is_vae=True,
  )
gamma = 0.1

# Set the device to either CUDA or CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
vae_model = vae_model.to(device)

# Initialize the optimizer for the generator
optimizer_G = torch.optim.Adam(vae_model.decoder.parameters(), lr=lr, betas=(b1, b2))

l1_loss = L1Loss()
l2_loss = MSELoss()

# Train the network
for epoch in range(EPOCHS):
        for x in train_loader:
            # Move input to device
            x = x.to(device, dtype=torch.float)

            # Zero the parameter gradients
            optimizer_G.zero_grad()

            # Forward pass
            z, mu, logvar = vae_model.encode(x)
            x_hat = vae_model.decode(z)

            # Reconstruction loss
            rec_loss = l1_loss(x, x_hat) + l2_loss(x, x_hat)


            # KL-divergence
            logvar = torch.flatten(logvar, start_dim=1)
            mu = torch.flatten(mu, start_dim=1)
            kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
            kl_div = kl_div.mean()

            # Total loss
            loss = rec_loss + gamma * kl_div

            # Backward pass
            loss.backward()
            optimizer_G.step()


            # Print progress
            if epoch % 10  == 0:
              with torch.no_grad():
                  # Turn the network in testing mode
                  vae_model.set_is_training(is_training=False)

                  # Initialize accumulators
                  l1_test_loss = 0
                  l2_test_loss = 0
                  kl_test_loss = 0
                  for i, x in enumerate(test_loader):
                      x = x.to(device, dtype=torch.float)

                      # Forward pass
                      z, mu, logvar = vae_model.encode(x)
                      x_hat = vae_model.decode(z)

                      # Reconstruction loss
                      l1_test_loss += l1_loss(x, x_hat)
                      l2_test_loss += l2_loss(x, x_hat)

                      # KL-divergence
                      logvar = torch.flatten(logvar, start_dim=1)
                      mu = torch.flatten(mu, start_dim=1)
                      kl_div_test = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                      kl_test_loss += kl_div_test.mean()

              # Turn the network back into training mode
              vae_model.set_is_training(is_training=True)

# Generate random samples from VAE model
vae_model.eval()
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
z = torch.randn(4, 8*(2**5), 8, 8, device=device)
samples_vae = vae_model.decode(z)
samples_vae = numpy_from_tensor(samples_vae)

# Plot samples
plt.figure()
for i in range(4):
  plt.subplot(4, 8, i+1)
  plt.imshow(np.squeeze(samples_vae[i]), cmap='gray')
  plt.axis('off')
plt.suptitle('Random samples from VAE model')
plt.show()

# Define the VAE-GAN model
vae_gan_model = VAE_GAN(
    encoder=Encoder(
      in_channels=1,
      depth=5,
      length=2,
      feature_size=8
    ),
    decoder=Decoder(
      in_channels=8 * (2 ** 5),
      depth=5,
      length=2,
      reconstruction_channels=1
    ),
    code_processor=SpatialVAECodeProcessor(
       feature_size=8,
       depth=5,
       is_training=True
    ),
    is_vae=True,
    discriminator=Discriminator(),
  )

gamma = 0.1

# Set the device to either CUDA or CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
vae_gan_model = vae_gan_model.to(device)

# Initialize the optimizer for the generator and discriminator
optimizer_G = torch.optim.Adam(vae_gan_model.decoder.parameters(), lr=lr, betas=(b1, b2))
optimizer_D = torch.optim.Adam(vae_gan_model.discriminator.parameters(), lr=lr, betas=(b1, b2))

l1_loss = L1Loss()
l2_loss = MSELoss()
# Initialize the adversarial loss function
adversarial_loss = nn.BCELoss()

# Train the network
for epoch in range(EPOCHS):
        for x in train_loader:
            # Move input to device
            x = x.to(device, dtype=torch.float)

            # Zero the parameter gradients
            optimizer_G.zero_grad()
            optimizer_D.zero_grad()

            # Forward pass
            z, mu, logvar = vae_gan_model.encode(x)
            x_hat = vae_gan_model.decode(z)
            D_x_hat = vae_gan_model.discriminator(x_hat)

            # Reconstruction loss
            rec_loss = l1_loss(x, x_hat) + l2_loss(x, x_hat)

            # Adversarial loss
            G_loss = adversarial_loss(D_x_hat, torch.ones_like(D_x_hat))

            # Total generator loss
            G_loss = rec_loss + gamma * G_loss

            # Backward pass
            G_loss.backward(retain_graph=True)
            optimizer_G.step()



            # KL-divergence
            logvar = torch.flatten(logvar, start_dim=1)
            mu = torch.flatten(mu, start_dim=1)
            kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
            kl_div = kl_div.mean()

            # Total discriminator loss
            D_loss = adversarial_loss(vae_gan_model.discriminator(x), torch.ones_like(D_x_hat)) + \
                         adversarial_loss(D_x_hat.detach(), torch.zeros_like(D_x_hat))

            # Backward pass
            D_loss.backward()
            optimizer_D.step()


            # Print progress
            if epoch % 10 == 0:
              with torch.no_grad():
                  # Turn the network in testing mode
                  vae_gan_model.set_is_training(is_training=False)

                  # Initialize accumulators
                  l1_test_loss = 0
                  l2_test_loss = 0
                  kl_test_loss = 0
                  adv_test_loss = torch.zeros(1, device=device)
                  for i, x in enumerate(test_loader):
                      x = x.to(device, dtype=torch.float)

                      # Forward pass
                      z, mu, logvar = vae_gan_model.encode(x)
                      x_hat = vae_gan_model.decode(z)
                      D_x_hat = vae_gan_model.discriminator(x_hat)

                      # Reconstruction loss
                      l1_test_loss += l1_loss(x, x_hat)
                      l2_test_loss += l2_loss(x, x_hat)

                      # KL-divergence
                      logvar = torch.flatten(logvar, start_dim=1)
                      mu = torch.flatten(mu, start_dim=1)
                      kl_div_test = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
                      kl_test_loss += kl_div_test.mean()

                      # Adversarial loss
                      adv_test_loss += adversarial_loss(D_x_hat, torch.ones_like(D_x_hat))

              # Turn the network back into training mode
              vae_gan_model.set_is_training(is_training=True)

# Generate random samples from VAE-GAN model
vae_gan_model.eval()
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
z = torch.randn(4, 8*(2**5), 8, 8, device=device)
samples_vae_gan = vae_gan_model.decode(z)
samples_vae_gan = numpy_from_tensor(samples_vae_gan)

# Plot samples
plt.figure()
for i in range(4):
  plt.subplot(4, 8, i+1)
  plt.imshow(np.squeeze(samples_vae_gan[i]), cmap='gray')
  plt.axis('off')
plt.suptitle('Random samples from VAE-GAN model')
plt.show()

"""### REPORT

When we visually inspect the generated samples, we can see that the VAE model generates blurred but recognisable sample images that are similar to the training data, with clear hand contours. On the other hand, the images generated by the VAE-GAN model are similar to the training data but contain more artefacts and noise, and the hand contours are not as good as those generated by the VAE model, but are more diverse than those generated by the VAE model. the VAE-GAN model is able to generate more diverse images because of the adversarial loss component of its target, encouraging the model to generate images that are closer to the distribution of the training data. However, they are also more distorted and noisy.
"""
